---
title: "Chamois"
author: "Franz Johann, Liangwen He, Matthias Theobald"
date: "18. Dezember 2015"
output: html_document
---

# About the data
We have received a dataset of 2679 observations from hunted Chamois in the Eastern Italian Alps in the region of Alto Adige (South Tirol). The shot animals are yearlings culled during the hunting season of their second year. The hunting season is from September to December. The data measured from each individual is 
- horn length,
- weight, and
- sex.

?density ?Jday

Also included in the dataset is the council where the animal was shot, which in turn belongs to one of five administrative areas. Furthermore, there are environmental data, aggregated at the level of either council or area.

## Description of Environmental Data

We have the geographic coordinate, elevation and aspect for each council. In the area level the substrate is seperated to two categories: siliceous and calcareous. As for weather data we have in the global climate scale North Atlantic Oscillation(nao) index, in the local scale there are particular temperature and precipitation for each season covered by the life history of killed chamois. The Normalized Difference Vegetation Index(NDVI) was used to reflect the food supply for chamois.
## Struggling with Data

The first dataset we received only included partial weather data. First, we wanted to know about the weather conditions of the winter during the pregnancy of the mother (first winter) but we only had data about the weather of the winter the yearling experienced (second winter).
Second, there was no weather data about the autumn the yearling experienced.
Third, while exploring the data, we found several inconsistencies in the weather data.

Because of that, we asked for a larger dataset including the weather data of the first winter during pregnancy and also asked for clarification on the issues with the weather station. We received a second dataset where the requested information was provided, but 1100 obsverations of shot animals were removed, so only 1560 were available. The researchers responsible for the data argued that probably the removed data was not reliable. Our argument though is that each and every observation is useful and should be included in the model.
We therefore set out to work on merging the two datasets and filling the holes in the old dataset with meaningful weather data from the second dataset.

```{r loading data, echo=FALSE, include=FALSE}
# load libraries
library(mgcv)

# helper function: inverse of intersect
outersect <- function(x, y) {
    sort(c(setdiff(x, y),
        setdiff(y, x)))
}

# read data
db_chamois1 <- read.csv("chamois1.csv", sep=";")
db_chamois2 <- read.csv("chamois2.csv", sep=";")

#rename columns so merging can work its magic
db_chamois1$Snow_cover_winter2 <- db_chamois1$Snow_cover_winter
db_chamois1$snow_winter2 <- db_chamois1$snow_winter
db_chamois1$twinter.max2 <- db_chamois1$twinter.max
db_chamois1$twinter.mean2 <- db_chamois1$twinter.mean
db_chamois1$twinter.min2 <- db_chamois1$twinter.min

# delete the old cloumns
db_chamois1$Snow_cover_winter <- NULL
db_chamois1$snow_winter <- NULL
db_chamois1$twinter.max <- NULL
db_chamois1$twinter.mean <- NULL
db_chamois1$twinter.min <- NULL

# delete columns excel has added
db_chamois2$X <- NULL
db_chamois2$X.1 <- NULL
db_chamois2$X.2 <- NULL

# merge the databases
db_merge <- merge(db_chamois1, db_chamois2, all.x=T)

# delete all unnecessary columns
drops <- c(
    "exc.date2", # excel numeric date
    "Julia.date", # year + Julian day
    "date", # year # Julian day + random number
    "x", # coordniates + small random step for spatial autocorrelation
    "y", # same
    "x2", # same
    "y2", # same
    "y_r", #same
    "x_r", #same
    "NS", # North-south facing component of aspect
    "EO", # East-West facing component of aspect
    "Nweight", # normalized weight
    "Nhorn", # normalized horn length
    "h_w", # ratio hor length to weight
    "index" # Indice of above ratio
)
db_merge <- db_merge[, !names(db_merge) %in% drops]

```

## About the second Dataset

Describing the new variables
```{r new columns, echo=FALSE}
# what columns are new in the new data set?
outersect(colnames(db_chamois1), colnames(db_chamois2))
```

```{r fixing weather, echo=FALSE}
# consistency of kills in councils: not every year a chamois was shot in every council
with(db_merge, tapply(horn, list(council_cod, year), length))
# we need the consistent council to select which weather data to use


# make weather data consistent
# select all weather data
weather_data <- c(
    "snow_winter1",
    "Snow_cover_winter1",
    "r_apr_mag_1",
    "r_giu_lug_1",
    "r_ago_set_1",
    "r_spring1",
    "r_newsummer1",
    "r_autumn",
    "snow_winter2",
    "Snow_cover_winter2",
    "r_apr_mag_2",
    "r_giu_lug_2",
    "r_ago_set_2",
    "r_spring2",
    "r_newsummer2",
    "twinter.min1",
    "twinter.max1",
    "twinter.mean1",
    "tspring1.min",
    "tspring1.max",
    "tspring1.mean",
    "tsummer1.min",
    "tsummer1.max",
    "tsummer1.mean",
    "tautumn.min",
    "tautumn.max",
    "tautumn.mean",
    "twinter.min2",
    "twinter.max2",
    "twinter.mean2",
    "tspring2.min",
    "tspring2.max",
    "tspring2.mean",
    "tsummer2.min",
    "tsummer2.max",
    "tsummer2.mean"
)

# weather data from council 27 for each year
station27 <- unique(db_merge[db_merge$council_cod==27, c("year", weather_data)]) # not okay: year2007
# for the weather data in autumn, council27 has 2 values for the year 2007
station10 <- unique(db_merge[db_merge$council_cod==10, c("year", weather_data)])
station8 <- unique(db_merge[db_merge$council_cod==8, c("year", weather_data)])
# the weather stations used in council 8 and 10 are not representative for the whole area

station39 <- unique(db_merge[db_merge$council_cod==39, c("year", weather_data)]) # ok, snow, T, and Prec are from the higher stations both
station49 <- unique(db_merge[db_merge$council_cod==49, c("year", weather_data)]) # same as 39
# representative!



# merge the new weather data set into the old one
# removing the old weather columns first
db <- merge(db_merge[, !names(db_merge) %in% weather_data], station39, by="year", all=F)


```


data exploration and visualisation

```{r}
## animal density
with(db, tapply(density, list(year, area_cod), unique))
# we have an animal density per administrative area per year  which is then 
# confirmed in the next year or changed.
```

```{r}
# Effect of NAO on winter weather
cor.test(db$nao_w, db$twinter.mean2)
cor.test(db$nao_w, db$twinter.min2)
cor.test(db$nao_w, db$snow_winter2)

```

```{r}
## spatial distribution of horn size, comparing elevation
# horn size
m1 <- gam(horn~s(x.council, y.council), data=db)
vis.gam(m1, plot.type = "contour")

# elevation, unweighted and interpolated!
m2 <- gam(q_media~s(x.council, y.council), data=db)
vis.gam(m2, plot.type = "contour", main="Elevation", xlab="", ylab="")

# distribution of councils by admin. area
with(db, points(x.council, y.council, col=area_cod, pch=20, cex=1.5))
with(db, legend("bottomright", legend=unique(area_cod), col=unique(area_cod), pch=20))
# no data in south-east and north-west!

with(db, tapply(horn, area_cod, mean)) # horn size per area
with(db, tapply(q_media, area_cod, mean)) # mean elevation per area
```

It is clearly visible that horn size in area number 3 is higher because of the lower mean elevation of that area.

```{r, eval=FALSE}
# selecting all weight data which are whole numbers
tol <- 1e-12
db$int_weight <- 0

db$int_weight[sapply(db$weight, function(y) min(abs(c(y%%1, y%%1-1))) < tol)] <- 1

sum(db$int_weight) # whole numbers in weight
length(db$int_weight) - sum(db$int_weight) # floating point numbers

# are the integers and floating point weigths evenly distributed over the councils?

plot(with(db, tapply(int_weight, council_cod, function(y) sum(y)/length(y))), type="h", cex=1.4,
    main="weight int / all", xlab="council", ylab="")

plot(with(db, tapply(int_weight, area_cod, function(y) sum(y)/length(y))), type="h", cex=1.4,
    main="weight int / all", xlab="area", ylab="")

``

